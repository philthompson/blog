<!DOCTYPE html>
<!--

- ensure non-learning AI player is somehow more random than the
    learning AI player (either less trained or intentionally
    made more random)

python backpropagation/gradient descent are from:
https://www.youtube.com/watch?v=9RN2Wr8xvro

with arbitrary number of hidden layers used for gradient descent influenced by:
https://stackoverflow.com/a/53323498/259456

-->
<html>
	<head>
		<script src="../p5-v1.9.0.min.js"></script>
		<script src="neural-network-model-leakyrelu-1710972634.js"></script>
		<script>
const dispWidth = 1100;
const dispHeight = dispWidth * .38;
const roundRectRadius = dispWidth * .05;
const padding = 22;
const pitsPerSide = 6;
const pitWidth = (dispWidth - (padding * (pitsPerSide + 2 + 1))) / (pitsPerSide + 2);
const pitHeight = (dispHeight - (padding * 3)) / 2;
const seedSize = 16;
let boardColor;
let pitColors = [];
let seedColors = [];
let seedColor;
let seedsInHand = [];
let destinationPitIndexes = [];

const WAITING_FOR_PLAYER = 0;
const PIECES_MOVING_FROM_HAND = 1;
const PIECES_MOVING_TO_BANK = 2;
const ADJUSTING_NEURAL_NETWORK_WEIGHTS = 10;
const GAME_OVER = -1;
const CANCEL_EVERYTHING = -100;
let donePrintingCancelOutput = false;
const SIMULATION_CTX = {
	'originalPlayerTurn': null,
	'originalState': null,
	'ownBank': null,
	'oppBank': null,
	'selectablePits': [],
	'pitWinProbability': null,
	'pitTotalSeeds': null, // the total number of seeds the player has the end of the game summed for all simulated games
	'ithSelectablePit': -1,
	'gamesPlayed': 0.0,
	'gamesWon': 0.0
};
let currentPlayerTurn = 0;
let currentState = WAITING_FOR_PLAYER;
let movingSeed = null;
const HUMAN_PLAYER_INDEX = -1;
const ML_PLAYER_NN_BY_INDEX = {
	0: null,
	1: null
};
const TRAIN_ML_PLAYER_INDEXES = [0]; // i don't think it would actually work to train both NNs and indexes 0 and 1
let runningSimulation = false;
let modelOutputParagraph;
let statusParagraph;
let gamesToSimulatePerScenario = 100;
let aiTrainingGamesToRun = 100;
let shouldUpdateNonTrainedMLPlayerAfterEveryGame = true;
let maxTrainingSize = 320;
// only train when the training data is a multiple of this size, and remove this many oldest items at a time
// if this is smaller, individual input-output pairs are trained upon more times
// for example, if maxTrainingSize=256, and multipleTrainingSize=64, then
//   each item in the training data will be trained upon in 4 cycles before
//   aging out of the training data, whereas if mulitpleTrainingSize=32 then
//   each item will be trained upon 8 times
let multipleTrainingSize = 32;
const recentInputsToTrainOn = [];
const recentOutputsToTrainOn = [];
let adjustWeightsChunkIterations = 1; // wow, training iterations are so slow with 4,608 hidden neurons...
let adjustWeightsChunks = 200; // return control to main thread very often, so break training into many small chunks
//let stopTrainingDistanceForSingleMove = 0.09; // we don't want to overfit the network for any single move, so keep this a bit high for now
//let stopTrainingDistanceForSingleMove = 0.25; // we don't want to overfit the network for any single move, so keep this a bit high for now
let   stopTrainingDistanceForSingleMove = 0.3; // we don't want to overfit the network for any single move, so keep this a bit high for now
let adjustWeightsChunkCounter = 0;
let learningTotalIterations = 0;
let prevAvgDistRounded = 0;
let randomNudgingFactor = 0.3;
let shouldDoRandomNudging = false;
let randomNudgesForThisTrainingData = 0;
//let trainingDataShuffledIndexes = [];
//let adjustWeightsTrainingDataIndex = 0;
// i have no idea about the strategy of mancala, so we are
//   starting from scratch with training data.  the neural
//   network will have to learn by playing itself.
// because the training data is self-taught, the oldest data
//   in the recent*ToTrainOn arrays reflect a worse player --
//   if the learning rate is too fast, the neural network will
//   be trained too much on those older inferior moves.  the
//   network will then tend to make worse moves, which might
//   impact the overall quality of the training data.  the network
//   may train itself into an inferior local minima.  instead,
//   by training slower, the model can slowly train itself while
//   the training data itself slowly improves.  that's the idea
//   anwyay behind a slow learning rate.
//let learningRate = 0.0000001; // seems way too slow
//let learningRate = 0.0000032; // might be too slow still
//let learningRate = 0.0000048; // slow, but might be fine eventually
//let learningRate = 0.000009;
//let learningRate = 0.000012;
//let learningRate = 0.00002;  // mostly seems fine, but avg dist slightly increases on some training iterations
//let learningRate = 0.000012; // mostly seems fine, but avg dist slightly increases on some training iterations
//let learningRate = 0.000006; // this seems too slow, and i guess avg dist can increase even if not stepping too far during gd
let   learningRate = 0.000009;
//let learningRate = 0.00003; // seemed fine, if a bit fast, for linear (not squared) initial "delta" calculation in learn()

const INITIAL_SEEDS_IN_PIT = 4;
const pits = [];
let capturedPits = [];

let fpsParagraph;
let fpsLastTime = 0;
const ANIMATION_FPS = 90;
const STILL_FPS = 1;


// thanks to https://gist.github.com/vaiorabbit/5657561
// 32 bit FNV-1a hash
// Ref.: http://isthe.com/chongo/tech/comp/fnv/
const FNV1_32A_INIT = 0x811c9dc5;
function fnv32a(str) {
	let hval = FNV1_32A_INIT;
	for (let i = 0; i < str.length; ++i) {
		hval ^= str.charCodeAt(i);
		hval += (hval << 1) + (hval << 4) + (hval << 7) + (hval << 8) + (hval << 24);
	}
	return hval >>> 0;
}
// version of above FNV-1a that doesn't take string
//   input -- instead it takes one 32-bit input,
//   mixes in each byte separately, and returns another
//   32-bit output
const MASK_32B_1 = 0b11111111000000000000000000000000;
const MASK_32B_2 = 0b00000000111111110000000000000000;
const MASK_32B_3 = 0b00000000000000001111111100000000;
const MASK_32B_4 = 0b00000000000000000000000011111111;
function fnv32a_32bitint(int32b) {
	let hval = FNV1_32A_INIT;
	hval ^= (int32b & MASK_32B_1);
	hval += (hval << 1) + (hval << 4) + (hval << 7) + (hval << 8) + (hval << 24);
	hval ^= (int32b & MASK_32B_2);
	hval += (hval << 1) + (hval << 4) + (hval << 7) + (hval << 8) + (hval << 24);
	hval ^= (int32b & MASK_32B_3);
	hval += (hval << 1) + (hval << 4) + (hval << 7) + (hval << 8) + (hval << 24);
	hval ^= (int32b & MASK_32B_4);
	hval += (hval << 1) + (hval << 4) + (hval << 7) + (hval << 8) + (hval << 24);
	return hval >>> 0;
}
function test_fnv32a_32bitint() {
	const buckets = [];
	for (let i = 0; i <= 10; i++) {
		buckets.push(0);
	}
	for (let i = 0; i < 10000; i++) {
		buckets[Math.floor(fasterRandom(0,10))] += 1;
	}
	console.log("random values 0-10, Math.floor(), then placed in buckets: [" + buckets + "]");
}
// this appears to confirm FNV-1a doesn't repeat itself
//   after 100 million iterations
function test_fnv32a_repeat(iters) {
	const origHash = fnv32a(str(Date.now()));
	let newHash = fnv32a_32bitint(origHash);
	for (let i = 0; i < iters-1; i++) {
		if (newHash === origHash) {
			console.log("repeat hash DETECTED after [" + (i+1) + "] iterations");
			return;
		}
		newHash = fnv32a_32bitint(origHash);
	}
	console.log("repeat hash not detected after [" + iters + "] iterations");
}

let fasterRandomUsage = 2000000;
let fasterRandomHash = null;
// since bit shifting clamps number values to 32-bit unsigned
//   values, the maximum value the hash can have is this
//   BUT since we want the upper bound to be exclusive, we'll
//   add one to this
const MAX_UNSIGNED_HASH = (0b11111111111111111111111111111111) + 1;
function fasterRandom(minInclusive, maxExclusive) {
	if (fasterRandomUsage++ > 1000000) {
		fasterRandomUsage = 0;
		fasterRandomHash = fnv32a(str(Date.now()));
		//console.log("re-seeded FNV-1a PRNG with the current time");
	}
	fasterRandomHash = fnv32a_32bitint(fasterRandomHash);
	const valueAsFrac = fasterRandomHash / MAX_UNSIGNED_HASH;
	return minInclusive + (valueAsFrac * (maxExclusive - minInclusive));
}

// thanks to https://stackoverflow.com/a/36481059/259456
const TWO_PI = 2.0 * Math.PI;
function fasterRandomGaussian(mean, stddev) {
	const u = 1 - fasterRandom(0, 1); // Converting [0,1) to (0,1]
	const v = fasterRandom(0, 1);
	const z = Math.sqrt(-2.0 * Math.log(u)) * Math.cos(TWO_PI * v);
	return (z * stddev) + mean;
}

function createShuffledArray(fromInclusive, toInclusive) {
	const ordered = [];
	for (let i = fromInclusive; i <= toInclusive; i++) {
		ordered.push(i);
	}
	const shuffled = [];
	let idx;
	for (let i = fromInclusive; i <= toInclusive; i++) {
		if (ordered.length == 1) {
			shuffled.push(ordered.pop());
		} else {
			idx = Math.floor(fasterRandom(0, ordered.length));
			shuffled.push(ordered.splice(idx, 1)[0]);
		}
	}
	return shuffled;
}

function swish(input) {
	return input / (1.0 + Math.exp(-input));
}

function swishDerivative(input) {
	const exp = Math.exp(-input);
	return (1 + exp + (input * exp)) / Math.pow(1 + exp, 2);
}

function sigmoid(input) {
	// sigmoid function, thanks to https://dev.to/venture/writing-a-neural-network-in-javascript-2020-intro-to-neural-networks-2c4n
	return 1.0 / (1.0 + Math.exp(-input));
}

// thanks to https://math.stackexchange.com/questions/78575/derivative-of-sigmoid-function-sigma-x-frac11e-x
function sigmoidDerivative(input) {
	const s = sigmoid(input);
	return s * (1 - s);
}

function leakyRelu(input) {
	return input <= 0 ? 0.05 * input : input;
}

function leakyReluDerivative(input) {
	return input <= 0 ? 0.05 : 1;
}

// thanks to https://stackoverflow.com/a/64816824/259456
function dotProduct(a, b) {
	return a.reduce((acc, val, idx) => acc + (val * b[idx]), 0.0);
}

function subtractArrays(a, b) {
	return a.map((val, idx) => val - b[idx]);
}

// thanks to https://stackoverflow.com/a/13241545/259456
function transposeArray(a) {
    return Object.keys(a[0]).map(function(c) {
        return a.map(function(r) { return r[c]; });
    });
}

// assume each array within a has same length as b
function multiplyArrays(a, b) {
	return a.map((val) => val.map((inner,idx) => inner * b[idx]));
}

// thanks to https://stackoverflow.com/a/61523756/259456
function matrixMultiply(a, b) {
	return a.map((row, i) =>
		b[0].map((_, j) =>
			row.reduce((acc, _, n) =>
				acc + a[i][n] * b[n][j], 0
			)
		)
	);
}

class Neuron {
	constructor(weights, bias_input) {
		this.weights = weights; // an array of floats
		this.bias_input = bias_input; // a number
	}

	process_input(inputs) {
		// start with the bias_input
		let sum = this.bias_input;
		// mulitply each input by its (corresponding by array position) weight
		inputs.forEach((value, index) => sum += value * this.weights[index]);
		// sigmoid function, thanks to https://dev.to/venture/writing-a-neural-network-in-javascript-2020-intro-to-neural-networks-2c4n
		//return 1.0 / (1.0 + Math.exp(-sum));
		//return sigmoid(sum);
		//return swish(sum);
		return leakyRelu(sum);
	}

	randomNudge(nudgeSize) {
		this.weights.forEach((w) => w *= fasterRandom(1/(1+nudgeSize), 1+nudgeSize));
		this.bias_input *= fasterRandom(1/(1+nudgeSize), 1+nudgeSize);
	}
}

class NeuronLayer {
	constructor(neurons, numberOfInputs, json = null) {
		if (json !== null) {
			this.numberOfInputs = json.numberOfInputs;
			this.neurons = [];
			for (let i = 0; i < json.neuronWeights.length; i++) {
				this.neurons.push(new Neuron(json.neuronWeights[i], json.neuronBias[i]));
			}
		} else {
			// initialize with random weights and biases
			// https://www.youtube.com/watch?v=8krd5qKVw-Q
			// - each weight is normally distributed around 0 w/ stanard deviation of 1
			// - then multiply each weight by sqrt(1/n) where n is the number of
			//     neurons in the layer
			const initFactor = Math.sqrt(1/neurons);
			this.numberOfInputs = numberOfInputs;
			this.neurons = [];
			for (let i = 0; i < neurons; i++) {
				let weights = [];
				for (let j = 0; j < numberOfInputs; j++) {
					weights.push(fasterRandomGaussian(0, 1) * initFactor);
				}
				//this.neurons.push(new Neuron(weights, random(-1, 1)));
				// initialize bias to 0?
				this.neurons.push(new Neuron(weights, 0.0));
			}
		}
	}

	export_to_json() {
		const json = {
			neuronWeights: [],
			neuronBias: []
		};
		for (const neuron of this.neurons) {
			json.neuronWeights.push(neuron.weights);
			json.neuronBias.push(neuron.bias_input);
		}
		return json;
	}

	process_input(inputs) {
		return this.neurons.map((n) => n.process_input(inputs));
	}

	adjust_weights() {
		for (const neuron of this.neurons) {
			neuron.adjust_weights();
		}
	}

	restore_prev_weights() {
		for (const neuron of this.neurons) {
			neuron.restore_prev_weights();
		}
	}
}

class NeuralNet {
	constructor(json = null, inputs = -1, inputNeurons = -1, hiddenLayerNeurons = -1, hiddenLayers = -1, outputNeurons = -1) {
		if (json !== null) {
			this.restore_from_json(json);
		} else {
			this.inputLayer = new NeuronLayer(inputNeurons, inputs);
			this.hiddenLayers = [];
			for (let i = 0; i < hiddenLayers; i++) {
				const hiddenLayerInputs = i == 0 ? inputNeurons : hiddenLayerNeurons;
				this.hiddenLayers.push(new NeuronLayer(hiddenLayerNeurons, hiddenLayerInputs));
			}
			this.outputLayer = new NeuronLayer(outputNeurons, hiddenLayerNeurons);
		}
	}

	restore_from_json(json) {
		this.inputLayer = new NeuronLayer(-1, -1, json.inputLayer);
		this.hiddenLayers = [];
		for (let i = 0; i < json.hiddenLayers.length; i++) {
			this.hiddenLayers.push(new NeuronLayer(-1, -1, json.hiddenLayers[i]));
		}
		this.outputLayer = new NeuronLayer(-1, -1, json.outputLayer);
	}

	export_to_json() {
		const json = {
			inputLayer: this.inputLayer.export_to_json(),
			hiddenLayers: [],
			outputLayer: this.outputLayer.export_to_json(),
		};
		for (const layer of this.hiddenLayers) {
			json.hiddenLayers.push(layer.export_to_json());
		}
		return JSON.stringify(json, null, "");
	}

	process_input(inputs) {
		let layerOutput = this.inputLayer.process_input(inputs);
		for (const layer of this.hiddenLayers) {
			layerOutput = layer.process_input(layerOutput);
		}
		return this.outputLayer.process_input(layerOutput);
	}

	get_current_outputs_dist(inputsArray, desiredOutputsArray) {
		let nnOutputs = null;
		let baselineDist = 0.0;
		for (let j = 0; j < inputsArray.length; j++) {
			// process input, and save the seed if it results in the closest yet output
			nnOutputs = this.process_input(inputsArray[j]);
			// use square of distance to penalize large distances more,
			//   and for more fine-grained tuning of small distances
			nnOutputs.forEach((val,idx) => baselineDist += Math.pow(desiredOutputsArray[j][idx] - val, 2));
		}
		return baselineDist;
	}

	get_current_outputs_dist_single(input, desiredOutput) {
		// process input, and save the seed if it results in the closest yet output
		let nnOutputs = this.process_input(input);
		let baselineDist = 0.0;
		// use square of distance to penalize large distances more,
		//   and for more fine-grained tuning of small distances
		nnOutputs.forEach((val,idx) => baselineDist += Math.pow(desiredOutput[idx] - val, 2));
		return baselineDist;
	}

	randomNudge(nudgeSize) {
		this.inputLayer.neurons.forEach((n) => n.randomNudge(nudgeSize));
		for (const hiddenLayer of this.hiddenLayers) {
			hiddenLayer.neurons.forEach((n) => n.randomNudge(nudgeSize));
		}
		this.outputLayer.neurons.forEach((n) => n.randomNudge(nudgeSize));
	}

	learnSingleInputOutput(iterations, input, desiredOutput) {
		for (let i = 0; i < iterations; i++) {

			// use latest weights to process all inputs
			let layerOutput = desiredOutput; //transposeArray(desiredOutput);
			let layerInput = input; //transposeArray(input);
			let layerInputs = [];
			layerInput = this.inputLayer.process_input(layerInput);
			layerInputs.push(layerInput);
			for (const hiddenLayer of this.hiddenLayers) {
				layerInput = hiddenLayer.process_input(layerInput);
				layerInputs.push(layerInput);
			}
			layerInput = this.outputLayer.process_input(layerInput);
			layerInputs.push(layerInput);

			// work backward through layers to apply gradient steps,
			//   starting here with the output of the outputLayer
			let delta = subtractArrays(layerInput, desiredOutput);
			// squared distance doesn't preserve the negative sign, which i think is an issue,
			//   but can the minus sign be replaced after finding the squared distance?
			//let delta = layerInput.map((val,idx) => Math.pow(val - desiredOutput[idx], 2));
			let temp;
			let nextLayer;
			for (let k = this.hiddenLayers.length; k >= 0; k--) {
				// don't need this anymore...
				//delta = delta.map((val, idx) => val * sigmoidDerivative(layerInputs[k+1][idx]));
				let outLayer;
				// the first layer, working backwards, doesn't use the sigmoid derivative, and
				//   also uses the output layer since it is one beyond the last hidden layer
				if (k == this.hiddenLayers.length) {
					outLayer = this.outputLayer;
					// one-dimensional arrays are matrix multiplied here to create a two-dimensional array
					// vertical delta @ horizontal neuron values --> 2D result
					temp = matrixMultiply(transposeArray([delta]), [layerInputs[k]]);
					temp.forEach((vals,nIdx) => vals.forEach((val,wIdx) => outLayer.neurons[nIdx].weights[wIdx] -= learningRate * val));
					delta.forEach((val,nIdx) => outLayer.neurons[nIdx].bias_input -= learningRate * val);
					nextLayer = outLayer;

				} else {
					outLayer = this.hiddenLayers[k];
					let weights = transposeArray(nextLayer.neurons.map((neuron) => neuron.weights));
					// two-dimensional weights array is matrix multiplied by one-dimensional here to create a one-dimensional array
					// 2D weights @ vertical delta -> 1D result
					temp = matrixMultiply(weights, transposeArray([delta]));
					temp = transposeArray(temp)[0];
					// two one-dimensional arrays are regular multipled to create a one-dimensional array
					//   where temp and sigmoid derivatives arrays are the same length
					//delta = layerInputs[k+1].map((val, idx) => temp[idx] * sigmoidDerivative(val))
					//delta = layerInputs[k+1].map((val, idx) => temp[idx] * swishDerivative(val))
					delta = layerInputs[k+1].map((val, idx) => temp[idx] * leakyReluDerivative(val))
					// one-dimensional arrays are matrix multiplied here to create a two-dimensional array
					// vertical delta @ horizontal neuron values --> 2D result
					temp = matrixMultiply(transposeArray([delta]), [layerInputs[k]]);
					temp.forEach((vals,nIdx) => vals.forEach((val,wIdx) => outLayer.neurons[nIdx].weights[wIdx] -= learningRate * val));
					delta.forEach((val,nIdx) => outLayer.neurons[nIdx].bias_input -= learningRate * val);
					nextLayer = outLayer;

				}

				//console.log("outLayer neuron weights after:");
				//for (const neuron of outLayer.neurons) {
				//	console.log("" + neuron.weights);
				//	break;
				//}
			}
			//console.log("completed learn iteration " + (i+1));
		}
	}

	learn(iterations, inputsArray, desiredOutputsArray) {
		for (let i = 0; i < iterations; i++) {

			let shuffledIndexes = createShuffledArray(0, inputsArray.length - 1);

			// since iterations are so slow, only train on half the inputs
			//   (after shuffling them) but do twice as many iterations
			//for (let j = 0; j < Math.floor(inputsArray.length/2); j++) {
			for (let j = 0; j < inputsArray.length; j++) {
				const input = inputsArray[shuffledIndexes[j]];
				const desiredOutput = desiredOutputsArray[shuffledIndexes[j]];

				// use latest weights to process all inputs
				let layerOutput = desiredOutput;//.slice(0); // getting undefined... maybe slice here for now...
				let layerInput = input;//.slice(0); // getting undefined... maybe slice here for now...
				let layerInputs = [];
				layerInput = this.inputLayer.process_input(layerInput);
				layerInputs.push(layerInput);
				for (const hiddenLayer of this.hiddenLayers) {
					layerInput = hiddenLayer.process_input(layerInput);
					layerInputs.push(layerInput);
				}
				layerInput = this.outputLayer.process_input(layerInput);
				layerInputs.push(layerInput);

				// work backward through layers to apply gradient steps,
				//   starting here with the output of the outputLayer
				let delta = subtractArrays(layerInput, desiredOutput);
				// squared distance doesn't preserve the negative sign, which i think is an issue,
				//   but can the minus sign be replaced after finding the squared distance?
				//let delta = layerInput.map((val,idx) => Math.pow(val - desiredOutput[idx], 2));
				//let delta = layerInput.map((val,idx) => Math.pow(val - desiredOutput[idx], 2) * (val > desiredOutput[idx] ? 1 : -1));
				let temp;
				let nextLayer;
				for (let k = this.hiddenLayers.length; k >= 0; k--) {
					// don't need this anymore...
					//delta = delta.map((val, idx) => val * sigmoidDerivative(layerInputs[k+1][idx]));
					let outLayer;
					// the first layer, working backwards, doesn't use the sigmoid derivative, and
					//   also uses the output layer since it is one beyond the last hidden layer
					if (k == this.hiddenLayers.length) {
						outLayer = this.outputLayer;
						// one-dimensional arrays are matrix multiplied here to create a two-dimensional array
						// vertical delta @ horizontal neuron values --> 2D result
						temp = matrixMultiply(transposeArray([delta]), [layerInputs[k]]);
						temp.forEach((vals,nIdx) => vals.forEach((val,wIdx) => outLayer.neurons[nIdx].weights[wIdx] -= learningRate * val));
						delta.forEach((val,nIdx) => outLayer.neurons[nIdx].bias_input -= learningRate * val);
						nextLayer = outLayer;

					} else {
						outLayer = this.hiddenLayers[k];
						let weights = transposeArray(nextLayer.neurons.map((neuron) => neuron.weights));
						// two-dimensional weights array is matrix multiplied by one-dimensional here to create a one-dimensional array
						// 2D weights @ vertical delta -> 1D result
						temp = matrixMultiply(weights, transposeArray([delta]));
						temp = transposeArray(temp)[0];
						// two one-dimensional arrays are regular multipled to create a one-dimensional array
						//   where temp and sigmoid derivatives arrays are the same length
						//delta = layerInputs[k+1].map((val, idx) => temp[idx] * sigmoidDerivative(val))
						//delta = layerInputs[k+1].map((val, idx) => temp[idx] * swishDerivative(val))
						delta = layerInputs[k+1].map((val, idx) => temp[idx] * leakyReluDerivative(val))
						// one-dimensional arrays are matrix multiplied here to create a two-dimensional array
						// vertical delta @ horizontal neuron values --> 2D result
						temp = matrixMultiply(transposeArray([delta]), [layerInputs[k]]);
						temp.forEach((vals,nIdx) => vals.forEach((val,wIdx) => outLayer.neurons[nIdx].weights[wIdx] -= learningRate * val));
						delta.forEach((val,nIdx) => outLayer.neurons[nIdx].bias_input -= learningRate * val);
						nextLayer = outLayer;

					}

					//console.log("outLayer neuron weights after:");
					//for (const neuron of outLayer.neurons) {
					//	console.log("" + neuron.weights);
					//	break;
					//}
				}
			}
			//console.log("completed learn iteration " + (i+1));
		}
	}
}

class SeedMovement {
	constructor(startPos, endPos, seed, destinationPitIndex) {
		this.seed = seed;
		this.startPos = startPos;
		this.endPos = endPos;
		this.destinationPitIndex = destinationPitIndex;
		this.fracComplete = runningSimulation ? 1.0 : 0.0;
		// take about 1/4 second to reach the end position
		this.fracStep = 4.0 / frameRate();
	}

	updateAndDraw() {
		fill(this.seed.color);
		this.fracComplete += this.fracStep;
		if (this.fracComplete > 1.0) {
			this.fracComplete = 1.0;
		}
		circle(lerp(this.startPos.x, this.endPos.x, this.fracComplete), lerp(this.startPos.y, this.endPos.y, this.fracComplete), seedSize);
		return this.fracComplete == 1.0;
	}
}

class Seed {
	constructor(color) {
		this.color = color;
	}
}

class Pit {
	constructor(x, y, width, height, seedCount, doSquareArrangement, playerIndex, isBank, index) {
		this.x = x;
		this.y = y;
		this.width = width;
		this.height = height;
		this.midX = this.x + (this.width / 2);
		this.midY = this.y + (this.height / 2);
		this.seeds = [];
		this.doSquareArrangement = doSquareArrangement;
		this.playerIndex = playerIndex;
		this.isBank = isBank;
		this.index = index;
		this.resetWithNewSeeds(seedCount);
	}

	resetWithNewSeeds(seedCount) {
		this.seeds = [];
		for (let i = 0; i < seedCount; i++) {
			this.seeds.push(new Seed(seedColors[this.playerIndex]));
		}
	}

	drawSeedCount() {
		//fill(pitColors[this.playerIndex]);
		//stroke(220,220,220);
		//strokeWeight(4);
		//fill(boardColor);
		fill(seedColors[this.playerIndex]);
		noStroke();
		textFont('Helvetica');
		textSize(dispWidth * 0.04);
		textAlign(CENTER, CENTER);
		text(this.seeds.length, this.midX, this.y + this.height - 24);
	}

	draw() {
		if (currentPlayerTurn == this.playerIndex) {
			stroke(200,200,200);
			strokeWeight(5);
		} else {
			noStroke();
		}
		fill(pitColors[this.playerIndex]);
		rect(this.x, this.y, this.width, this.height, roundRectRadius);
		noStroke();
		fill(seedColor);
		drawSeeds(this.midX, this.midY, this.seeds, this.doSquareArrangement);
	}

	wasClicked(clickX, clickY) {
		return currentState == WAITING_FOR_PLAYER && !this.isBank &&
			currentPlayerTurn == this.playerIndex &&
			this.seeds.length > 0 &&
			clickX > this.x && clickX < (this.x + this.width) &&
			clickY > this.y && clickY < (this.y + this.height);
	}

	getNextSeedPos() {
		return drawSeeds(this.midX, this.midY, this.seeds, this.doSquareArrangement, true);
	}

	getLastSeedPos() {
		return drawSeeds(this.midX, this.midY, this.seeds, this.doSquareArrangement, false);
	}

	addSeed(seed) {
		this.seeds.push(seed);
	}
}

function setup() {
	frameRate(STILL_FPS);
	noStroke();
	boardColor = color(50,50,50);
	pitColors[0] = color(150,130,130);
	seedColors[0] = color(170,85,85);
	pitColors[1] = color(130,130,150);
	seedColors[1] = color(85,85,170);
	seedColor = color(150,150,150);
	createCanvas(dispWidth, dispHeight);
	//let pitX = padding + pitWidth + padding;
	let pitX = padding;
	for (let i = 0; i < (pitsPerSide * 2) + 2; i++) {
		// left-hand side large "bank" pit
		if (i == 0) {
			pits.push(new Pit(pitX, padding, pitWidth, dispHeight - padding - padding, 0, false, 1, true, i));
			pitX += padding + pitWidth;

		// right-hand side large "bank" pit
		} else if (i == pitsPerSide + 1) {
			pits.push(new Pit(pitX, padding, pitWidth, dispHeight - padding - padding, 0, false, 0, true, i));
			pitX -= padding + pitWidth;

		// bottom row of pits
		} else if (i <= pitsPerSide) {
			pits.push(new Pit(pitX, padding + pitHeight + padding, pitWidth, pitHeight, INITIAL_SEEDS_IN_PIT, true, 0, false, i));
			pitX += padding + pitWidth;

		// top row of pits
		} else {
			pits.push(new Pit(pitX, padding, pitWidth, pitHeight, INITIAL_SEEDS_IN_PIT, true, 1, false, i));
			pitX -= padding + pitWidth;
		}
	}
	fpsParagraph = createElement('p');
	statusParagraph = createElement('p');
	modelOutputParagraph = createElement('p');

	// create neural networks, where, for now, only player index 0 will be
	//   trained -- the other will be loaded from json and then left alone
	// after implementing Xavier Initialization, 18 inputs, 52 per 64 hidden layer, seems like it can approach 0.8 avg dist/err
	// after implementing Xavier Initialization, fewer wider layers may work better without getting NaN problems...
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 52, hiddenLayers = 64, outputNeurons = pitsPerSide);
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 128, hiddenLayers = 16, outputNeurons = pitsPerSide);
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 192, hiddenLayers = 24, outputNeurons = pitsPerSide);
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 256, hiddenLayers = 8, outputNeurons = pitsPerSide);
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 512, hiddenLayers = 6, outputNeurons = pitsPerSide);
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 768, hiddenLayers = 6, outputNeurons = pitsPerSide);
	// while learning the initial 28 moves, this stalled at avg dist/err of about 0.91
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 1024, hiddenLayers = 8, outputNeurons = pitsPerSide);
	// while learning the initial 16 moves, this stalled at avg dist/err of about 0.98
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 64, hiddenLayers = 32, outputNeurons = pitsPerSide);
	// while learning the initial 16 moves, this stalled at avg dist/err of about 0.82 (this is promising!)
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 60, hiddenLayers = 48, outputNeurons = pitsPerSide);
	// while learning the initial 20 moves, this stalled at avg dist/err of about 0.87 (this is promising!)
	// with swish(), it did great for 32 moves, then stalled at 48 moves with avg err of 1.06 (this is promising!)
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 60, hiddenLayers = 64, outputNeurons = pitsPerSide);
	// with swish(), doing high 0.80s or low 0.90s with 64 moves (pretty good)
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 62, hiddenLayers = 72, outputNeurons = pitsPerSide);
	// with swish(), stalled at 1.29 while learning the intial 56 moves
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 64, hiddenLayers = 78, outputNeurons = pitsPerSide);
	// still testing this one
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 58, hiddenLayers = 92, outputNeurons = pitsPerSide);
	// small for testing (worked better than expected, so it appears only number of hidden layers, not size, matters here)
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 16, hiddenLayers = 92, outputNeurons = pitsPerSide);
	// with leakyRelu(), had about 0.67 avg dist/err at 64 inputs
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 18, hiddenLayers = 300, outputNeurons = pitsPerSide);
	// with leakyRelu(), had about 0.67 avg dist/err at 48 inputs
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 48, hiddenLayers = 64, outputNeurons = pitsPerSide);

	// this one seems to be able to reach 0.33 avg dist/err with 288 inputs!
	//ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 256, hiddenLayers = 6, outputNeurons = pitsPerSide);
	//ML_PLAYER_NN_BY_INDEX[1] = new NeuralNet(json = null, inputs = (pitsPerSide*2)+6, inputNeurons = (pitsPerSide*2)+6, hiddenLayerNeurons = 16, hiddenLayers = 3, outputNeurons = pitsPerSide);

	// reconstruct neural network(s) from previously-exported json
	ML_PLAYER_NN_BY_INDEX[0] = new NeuralNet(json = LATEST_NN_MODEL);
	ML_PLAYER_NN_BY_INDEX[1] = new NeuralNet(json = LATEST_NN_MODEL);

	if (PREV_INPUTS) {
		if (PREV_OUTPUTS) {
			for (const prev_input of PREV_INPUTS) {
				// ensure inputs are normalized from 0.0-1.0 (where we divide the number of seeds per pit by 48, the overall number of seeds)
				// the JSON contains whole seed numbers to keep the file size small when/if
				//   the training set becomes very large
				if (prev_input.some((v) => v > 1.0)) {
					recentInputsToTrainOn.push(prev_input.map((v) => v/(INITIAL_SEEDS_IN_PIT * pitsPerSide * 2)));
				} else {
					recentInputsToTrainOn.push(prev_input);
				}
			}
			console.log("loaded " + recentInputsToTrainOn.length + " PREV_INPUTS");
			for (const prev_output of PREV_OUTPUTS) {
				recentOutputsToTrainOn.push(prev_output);
			}
			console.log("loaded " + recentOutputsToTrainOn.length + " PREV_OUTPUTS");
		}
	}
}

function drawBoard() {
	noStroke();
	background(120,120,120);
	fill(boardColor);
	rect(0, 0, width, height, roundRectRadius);

	for (const pit of pits) {
		pit.draw();
		if (currentPlayerTurn < 0 && pit.isBank) {
			pit.drawSeedCount();
		}
	}
}

function shouldTurn(doSquareArrangement, i) {
	if (doSquareArrangement) {
		return [1,2,4,6,9,12,16,20,25,30,36,42,49,56,64,72,81].indexOf(i) > -1;
	} else {
		return [0,3,4,8,10,15,18,24,28,35,40,48,54,63,70,80,88,99].indexOf(i) > -1;
	}
}

function drawSeeds(atPosX, atPosY, seeds, doSquareArrangement, onlyGetNextPos = false) {
	let xPos = atPosX;
	let yPos = atPosY;
	let stepAngle = 0;
	let xStep = seedSize * cos(stepAngle);
	let yStep = seedSize * sin(stepAngle);
	let lastX = 0;
	let lastY = 0;
	for (let i = 0; i < seeds.length; i++) {
		if (!onlyGetNextPos) {
			fill(seeds[i].color);
			circle(xPos, yPos, seedSize);
		}
		lastX = xPos;
		lastY = yPos;
		//fill(0,0,0);
		//textSize(10);
		//textAlign(CENTER, CENTER);
		//text(""+i, xPos, yPos);
		const ithSqrt = Math.sqrt(i+1);
		// turn 1/4 turn on square numbered seeds
		//if (Math.floor(ithSqrt) == ithSqrt) {
		if (shouldTurn(doSquareArrangement, i)) {
			stepAngle += (PI/2);
			xStep = seedSize * cos(stepAngle);
			yStep = seedSize * sin(stepAngle);
		}
		xPos += xStep;
		yPos += yStep;
	}
	if (onlyGetNextPos) {
		return createVector(xPos, yPos);
	} else {
		return createVector(lastX, lastY);
	}
}

// draw the number of held seeds
function drawHand() {
	//cursor(HAND);
	//stroke(255,255,255,60);
	//fill(200,70,70,70);
	//textSize(100);
	//textAlign(CENTER, CENTER);
	//text('×', mouseX, mouseY);
	return drawSeeds(mouseX, mouseY, seedsInHand, true);
}

function playerTurnIsOver() {
	currentState = WAITING_FOR_PLAYER;
	//frameRate(STILL_FPS);
	// XOR with 1 to alternate between 1 and 0
	currentPlayerTurn = currentPlayerTurn ^ 1;
	// check end game: if the player has no pits with seeds,
	//   the other player captures all their pits' seeds
	let somePitHasSeeds = false;
	for (const pit of pits) {
		if (pit.playerIndex == currentPlayerTurn && !pit.isBank && pit.seeds.length > 0) {
			somePitHasSeeds = true;
			break;
		}
	}
	if (!somePitHasSeeds) {
		// if neither player has any seeds in their pits, the game is over
		let gameIsOver = true;
		for (const pit of pits) {
			if (!pit.isBank && pit.seeds.length > 0) {
				gameIsOver = false;
				break;
			}
		}
		if (gameIsOver) {
			currentState = GAME_OVER;
			//frameRate(STILL_FPS);
			currentPlayerTurn = -1;
			if (TRAIN_ML_PLAYER_INDEXES.length > 0 && ML_PLAYER_NN_BY_INDEX[0] !== null && ML_PLAYER_NN_BY_INDEX[1] !== null) {
				if (!runningSimulation) {
					aiTrainingGamesToRun -= 1;
					// output the neural network weights
					modelOutputParagraph.html("nn model with " + aiTrainingGamesToRun + " games left to train on");
					for (const aiIdx of TRAIN_ML_PLAYER_INDEXES) {
						//const contentAlreadyPresent = modelOutputParagraph.html();
						//console.log("current state of trained AI for player index [" + aiIdx + "]:");
						//console.log(ML_PLAYER_NN_BY_INDEX[aiIdx].export_to_json());
						modelOutputParagraph.html(modelOutputParagraph.html() + '<br/><br/>const LATEST_NN_MODEL = ' + ML_PLAYER_NN_BY_INDEX[aiIdx].export_to_json() + ';');
					}
					printRecentTrainingData();
					// if more games left to run, restart
					if (aiTrainingGamesToRun > 0) {
						// update the non-training AI NN
						if (shouldUpdateNonTrainedMLPlayerAfterEveryGame) {
							const trainedMLPlayerIndex = TRAIN_ML_PLAYER_INDEXES[0];
							const nonTrainedMLPlayerIndex = trainedMLPlayerIndex ^ 1; // XOR with 1 to alternate between 1 and 0
							const trainedMLNN = ML_PLAYER_NN_BY_INDEX[trainedMLPlayerIndex].export_to_json();
							ML_PLAYER_NN_BY_INDEX[nonTrainedMLPlayerIndex] = new NeuralNet(json = JSON.parse(trainedMLNN));
							console.log("updated non-training ML NeuralNet, restarting game (" + aiTrainingGamesToRun + " games left to train on)");
						} else {
							console.log("restarting game (" + aiTrainingGamesToRun + " games left to train on)");
						}
						restartGame();
					} else {
						console.log("done training");
						frameRate(STILL_FPS);
					}
				}
			}
		} else {
			currentState = PIECES_MOVING_TO_BANK;
			frameRate(ANIMATION_FPS);
			capturedPits = [];
			for (const pit of pits) {
				if (pit.playerIndex != currentPlayerTurn && !pit.isBank && pit.seeds.length > 0) {
					capturedPits.push(pit);
				}
			}
			// XOR with 1 to alternate between 1 and 0
			currentPlayerTurn = currentPlayerTurn ^ 1;
		}
	}
}

function draw() {
	if (currentState == CANCEL_EVERYTHING) {
		frameRate(STILL_FPS);
		if (!donePrintingCancelOutput) {
			statusParagraph.html("stopped");
			printRecentTrainingData();
			donePrintingCancelOutput = true;
		}
		return;
	}
	// don't need to draw the board for every simulated game,
	//   but we always need to draw it when not simulating games
	if (!runningSimulation || fasterRandom(0.0,1.0) < 0.001) {
		drawBoard();
	}
	const lastSeedInHandPos = drawHand();
	if (currentState == PIECES_MOVING_FROM_HAND) {
		if (movingSeed === null) {
			if (seedsInHand.length > 0) {
				const destinationPitIndex = destinationPitIndexes.shift();
				const destinationPos = pits[destinationPitIndex].getNextSeedPos();
				movingSeed = new SeedMovement(lastSeedInHandPos, destinationPos, seedsInHand.pop(), destinationPitIndex);
			} else {
				playerTurnIsOver();
			}
		}
		if (movingSeed !== null) {
			const doneMoving = movingSeed.updateAndDraw();
			if (doneMoving) {
				const destPit = pits[movingSeed.destinationPitIndex];
				destPit.addSeed(movingSeed.seed);
				movingSeed = null;
				// if this moved seed was the last seed in the hand,
				//   check if the destination pit is owned by the
				//   moving player and has only 1 seed.  if so, then
				//   that player captures that seed and all the seeds
				//   in the opposite pit.
				if (seedsInHand.length === 0 && destPit.playerIndex == currentPlayerTurn) {
					// if the last seed is placed in the player's bank, that
					//   player gets another turn
					if (destPit.isBank) {
						// switch player here, then immediately switch again
						//   in playerTurnIsOver() -- this is needed in case
						//   the player ends in their bank but has no remaining
						//   seeds (playerTurnIsOver() will end the game)
						currentPlayerTurn = currentPlayerTurn ^ 1;
						playerTurnIsOver();
					} else if (destPit.seeds.length === 1) {
						capturedPits = [destPit];
						const rightHandBankIndex = pitsPerSide + 1;
						// if the pit index is less than the midpoint of the pits array, it's
						//   in the bottom row
						if (destPit.index < pits.length / 2) {
							const distToMidBank = rightHandBankIndex - destPit.index;
							const oppositePitIndex = rightHandBankIndex + distToMidBank;
							capturedPits.push(pits[oppositePitIndex]);
						} else {
							const distToMidBank = destPit.index - rightHandBankIndex;
							const oppositePitIndex = rightHandBankIndex - distToMidBank;
							capturedPits.push(pits[oppositePitIndex]);
						}
						currentState = PIECES_MOVING_TO_BANK;
						frameRate(ANIMATION_FPS);
					}
				}
			}
		}
	} else if (currentState == PIECES_MOVING_TO_BANK) {
		// similar to "moving from hand" state
		const destBankPitIndex = currentPlayerTurn == 1 ? 0 : pitsPerSide + 1;
		if (movingSeed === null) {
			if (capturedPits.length > 0 && capturedPits[0].seeds.length > 0) {
				const startPos = capturedPits[0].getLastSeedPos();
				const destinationPos = pits[destBankPitIndex].getNextSeedPos();
				movingSeed = new SeedMovement(startPos, destinationPos, capturedPits[0].seeds.pop(), destBankPitIndex);
			} else if (capturedPits.length > 1 && capturedPits[1].seeds.length > 0) {
				capturedPits.shift();
			} else {
				playerTurnIsOver();
			}
		}
		if (movingSeed !== null) {
			const doneMoving = movingSeed.updateAndDraw();
			if (doneMoving) {
				const destPit = pits[movingSeed.destinationPitIndex];
				destPit.addSeed(movingSeed.seed);
				movingSeed = null;
			}
		}
	} else if (currentState == WAITING_FOR_PLAYER && ML_PLAYER_NN_BY_INDEX[currentPlayerTurn] !== null) {
		playAITurnOrStartTraining();
	} else if (currentState == GAME_OVER && runningSimulation) {
		playAITurnOrStartTraining();
	} else if (currentState == ADJUSTING_NEURAL_NETWORK_WEIGHTS) {
		adjustWeightsInChunks();
	}
	//if (fasterRandom(0,10) < 1.0) {
	//	const fpsTimeEpochMs = Date.now();
	//	if (fpsTimeEpochMs - fpsLastTime > 1000) {
	//		fpsLastTime = fpsTimeEpochMs;
	//		fpsParagraph.html(round(frameRate()));
	//	}
	//}
}

function printRecentTrainingData() {
	let inputsCopy = recentInputsToTrainOn.slice(-maxTrainingSize);
	// to keep file size small, use integer number of seeds in the input
	//   rather than fraction of overall number of seeds
	// to convert back from normalized 0.0-1.0 seeds values to whole seeds
	//   counts in the input arrays, multiply by 48 (overall number of seeds)
	modelOutputParagraph.html(modelOutputParagraph.html() + '<br/><br/>const PREV_INPUTS = ' + JSON.stringify(inputsCopy.map((arr) => arr.map((v) => Math.round(v * (INITIAL_SEEDS_IN_PIT * pitsPerSide * 2))))) + ';');
	modelOutputParagraph.html(modelOutputParagraph.html() + '<br/><br/>const PREV_OUTPUTS = ' + JSON.stringify(recentOutputsToTrainOn.slice(-maxTrainingSize)) + ';');
}

function appendNewTrainingData(inputs, outputs) {
	// convert back to integer number of seeds for less error-prone integer comparison
	const inputsStr = inputs.map((v) => Math.round(v * (INITIAL_SEEDS_IN_PIT * pitsPerSide * 2))).join('-');
	const dupeIndexes = [];
	for (let i = 0; i < recentInputsToTrainOn.length; i++) {
		const prevStr = recentInputsToTrainOn[i].map((v) => Math.round(v * (INITIAL_SEEDS_IN_PIT * pitsPerSide * 2))).join('-');
		if (prevStr == inputsStr) {
			dupeIndexes.push(i);
			console.log("removing duplicate older training data input: " + prevStr + " -> " + recentOutputsToTrainOn[i]);
		}
	}
	// remove all matching previous copies of this input, but
	//   in REVERSE (descending) order to ensure the indexes continue to
	//   work as we remove matches
	const dupeIndexesRev = dupeIndexes.reverse();
	for (const idx of dupeIndexesRev) {
		//console.log("removing duplicate previous input");
		recentInputsToTrainOn.splice(idx, 1);
		recentOutputsToTrainOn.splice(idx, 1);
	}
	recentOutputsToTrainOn.push(outputs);
	// return the new length of the inputs array
	console.log("appending new training data entry: " + inputsStr + " -> " + outputs);
	return recentInputsToTrainOn.push(inputs);
}

function mouseClicked() {
	if (currentState == WAITING_FOR_PLAYER) {
		for (const pit of pits) {
			if (pit.wasClicked(mouseX, mouseY)) {
				selectPitForPlay(pit);
				break;
			}
		}
	}
}

function selectPitForPlay(pit) {
	seedsInHand = pit.seeds;
	pit.seeds = [];
	currentState = PIECES_MOVING_FROM_HAND;
	frameRate(ANIMATION_FPS);
	destinationPitIndexes = [];
	let pitCursor = pit.index;
	for (let i = 0; i < seedsInHand.length; i++) {
		pitCursor += 1;
		if (pitCursor >= pits.length) {
			pitCursor = 0;
		}
		if (pits[pitCursor].isBank && pits[pitCursor].playerIndex != currentPlayerTurn) {
			i -= 1; // re-do this seed if we have to skip the other player's bank
			continue;
		}
		destinationPitIndexes.push(pitCursor);
	}
}

// 0 13 12 11 10  9  8
//    1  2  3  4  5  6  7
const TOTAL_SEEDS_OVERALL = INITIAL_SEEDS_IN_PIT * pitsPerSide * 2;
function getNNInputs() {
	// ensure inputs are normalized from 0.0-1.0 (where we divide the number of seeds per pit by 48, the overall number of seeds)
	let inputs = pits.map((pit) => pit.seeds.length / TOTAL_SEEDS_OVERALL);
	// if currentPlayerTurn == 1, we need to swap the inputs around so player
	//   1 gets the same inputs that player 0 would get
	if (currentPlayerTurn == 1) {
		// start with the opponent's bank
		let swappedInputs = [inputs[pitsPerSide+1]];
		// then do own pits
		// use strange "spread syntax" to concat the slice onto the end of the existing array
		swappedInputs.push(...inputs.slice(pitsPerSide+2, pitsPerSide+pitsPerSide+2));
		// then do own bank
		swappedInputs.push(inputs[0]);
		// finally, do oppoent's pits
		swappedInputs.push(...inputs.slice(1, pitsPerSide+1));
		inputs = swappedInputs;
	}
	// also add inputs for each player's total number of seeds
	playerSeeds = [0, 0];
	pits.forEach((pit) => playerSeeds[pit.playerIndex] += pit.seeds.length);
	// XOR with currentPlayerTurn to swap 0 and 1 if currentPlayerTurn == 1
	inputs.push(playerSeeds[0 ^ currentPlayerTurn] / TOTAL_SEEDS_OVERALL);
	inputs.push(playerSeeds[1 ^ currentPlayerTurn] / TOTAL_SEEDS_OVERALL);
	// also add inputs for each player's total number of non-bank seeds
	playerNonBankSeeds = [0, 0];
	pits.forEach((pit) => playerNonBankSeeds[pit.playerIndex] += pit.isBank ? 0 : pit.seeds.length);
	inputs.push(playerNonBankSeeds[0 ^ currentPlayerTurn] / TOTAL_SEEDS_OVERALL);
	inputs.push(playerNonBankSeeds[1 ^ currentPlayerTurn] / TOTAL_SEEDS_OVERALL);
	return inputs;
}

function playAITurnOrStartTraining() {
	// if training this AI player, simulate the rest of the game
	//   based on selecting each valid pit
	if (!runningSimulation && TRAIN_ML_PLAYER_INDEXES.indexOf(currentPlayerTurn) > -1) {

		if (SIMULATION_CTX.ithSelectablePit == -1) {
			SIMULATION_CTX.originalPlayerTurn = currentPlayerTurn;
			SIMULATION_CTX.originalState = pits.map((p) => p.seeds.slice(0));
			SIMULATION_CTX.ownBank = pits.filter((p) => p.playerIndex == currentPlayerTurn && p.isBank)[0];
			SIMULATION_CTX.oppBank = pits.filter((p) => p.playerIndex != currentPlayerTurn && p.isBank)[0];
			SIMULATION_CTX.selectablePits = pits.filter((p) => p.playerIndex == currentPlayerTurn && !p.isBank && p.seeds.length > 0);
			SIMULATION_CTX.pitWinProbability = SIMULATION_CTX.selectablePits.map((p) => 0.0);
			SIMULATION_CTX.pitTotalSeeds = SIMULATION_CTX.selectablePits.map((p) => 0.0);
			SIMULATION_CTX.gamesToSimulate = gamesToSimulatePerScenario;
			SIMULATION_CTX.ithSelectablePit = -1;
			SIMULATION_CTX.gamesPlayed = 0.0;
			SIMULATION_CTX.gamesWon = 0.0;
			runningSimulation = true;
			currentState = GAME_OVER; // set runningSimulation AND GAME_OVER to kick off the simulations below
			return;

		// if all games for all selectable pits have been simulated, use the results
		//   as training data to adjust model weights
		} else if (SIMULATION_CTX.ithSelectablePit < SIMULATION_CTX.selectablePits.length) {
			console.log("should not be here");
			return;
		}

		const allMovesGiveZeroWins = SIMULATION_CTX.pitWinProbability.every((val) => val == 0.0);
		const bestPitWins = SIMULATION_CTX.pitWinProbability.reduce((acc,val) => Math.max(acc,val), 0);
		console.log("adjusting weights with bestPitWins=" + bestPitWins + "...");
		const bestPitIndexes = [];
		for (let i = 0; i < SIMULATION_CTX.pitWinProbability.length; i++) {
			if (SIMULATION_CTX.pitWinProbability[i] == bestPitWins) {
				bestPitIndexes.push(SIMULATION_CTX.selectablePits[i].index);
			}
		}
		// maximum number of total seeds for the best pits by win probability
		const maxTotalSeeds = bestPitIndexes.reduce((acc, bestPitIdx) => Math.max(acc, SIMULATION_CTX.pitTotalSeeds[bestPitIdx]), 0);
		if (bestPitIndexes.length > 1) {
			console.log("more than one move is best, having equal win probability and final seed count [" + maxTotalSeeds + "]");
		}
		const bestWinPitsWithInferiorTotalSeeds = [];
		for (let i = 0; i < bestPitIndexes; i++) {
			if (SIMULATION_CTX.pitTotalSeeds[bestPitIndexes[i]] < maxTotalSeeds) {
				bestWinPitsWithInferiorTotalSeeds.push(bestPitIndexes[i]);
			}
		}
		if (bestWinPitsWithInferiorTotalSeeds.length > 0) {
			console.log("eliminating [" + bestWinPitsWithInferiorTotalSeeds.length + "] move(s) with best win probability but fewer than maximum final seed count");
		}
		const bestPitIndexesWithBestSeedCount = bestPitIndexes.filter(bestPitIdx => !bestWinPitsWithInferiorTotalSeeds.includes(bestPitIdx));


		// ensure inputs are normalized from 0.0-1.0 (where we divide the number of seeds per pit by 48, the overall number of seeds)
		const inputs = getNNInputs();
		let desiredOutputs = [];
		const desiredMoveOutputValue = 1.0 / bestPitIndexes.length;
		if (desiredMoveOutputValue != 1.0) {
			console.log("using [" + desiredMoveOutputValue + "] for desiredMoveOutputValue, which is usually 1.0");
		}
		// we want the nn to output a sum of 1.0 for all the pits tied with the best win probability,
		//   and 0.0 otherwise
		for (let i = 0; i < pitsPerSide; i++) {
			if (bestPitIndexesWithBestSeedCount.indexOf(getPitIndexForNeuralNetworkOutputIndex(i)) > -1) {
				desiredOutputs[i] = desiredMoveOutputValue;
			} else {
				desiredOutputs[i] = 0.0;
			}
		}
		if (allMovesGiveZeroWins) {
			console.log("NOT adjusting weights since a win is impossible (perhaps train for highest total in bank instead here?)");
			playAITurn();
			SIMULATION_CTX.ithSelectablePit = -1;
		} else {
			// since an input state may already exist in the training
			//   data, we need to remove any instances of that first
			//   before appending this latest output for it (assuming
			//   the model is better trained now than when it was
			//   originally inserted)
			if (appendNewTrainingData(inputs, desiredOutputs) > maxTrainingSize) {
				// drop (multipleTrainingSize-1) oldest inputs and outputs to force us to add (multipleTrainingSize-1) new moves to the training data
				for (let i = 0; i < multipleTrainingSize - 1; i++) {
					recentOutputsToTrainOn.shift();
					recentInputsToTrainOn.shift();
				}
			}
			const ai = ML_PLAYER_NN_BY_INDEX[currentPlayerTurn];

			if (recentInputsToTrainOn.length == 0 || recentInputsToTrainOn.length % multipleTrainingSize != 0) {
				console.log("NOT adjusting weights since we do not have a multiple of " + multipleTrainingSize + ", moves to train on (" + recentInputsToTrainOn.length + ")");
				playAITurn();
				SIMULATION_CTX.ithSelectablePit = -1;
				return;
			}
			//const inputs = getNNInputs();
			const outputs = ai.process_input(inputs);
			console.log("nn outputs now [" + outputs.map((v) => roundToDecimalPlaces(v, 4)) + "]...");
			currentState = ADJUSTING_NEURAL_NETWORK_WEIGHTS;
			// since we use the main draw() loop to run weight adjustment in chunks,
			//   (in order to keep UI thread responsive) we set the frame rate
			//   to the faster animation rate here
			frameRate(ANIMATION_FPS);
			// reset some things before starting first training epoch
			adjustWeightsChunkCounter = 0;
			randomNudgesForThisTrainingData = 0;
			prevAvgDistRounded = Infinity;
			learningTotalIterations = 0;
			// the next few calls to draw() will call adjustWeightsInChunks()
			return;
		}

	} else if (runningSimulation && currentState == GAME_OVER) {
		runningSimulation = false;
		// if a simulated game has ended, track the result and restore the state
		if (SIMULATION_CTX.ithSelectablePit >= 0) {
			SIMULATION_CTX.gamesPlayed += 1.0;
			SIMULATION_CTX.pitTotalSeeds[SIMULATION_CTX.ithSelectablePit] += SIMULATION_CTX.ownBank.seeds.length;
			if (SIMULATION_CTX.ownBank.seeds.length > SIMULATION_CTX.oppBank.seeds.length) {
				SIMULATION_CTX.gamesWon += 1.0;
			}
			// restore state
			for (let origStatePitIdx = 0; origStatePitIdx < SIMULATION_CTX.originalState.length; origStatePitIdx++) {
				pits[origStatePitIdx].seeds = SIMULATION_CTX.originalState[origStatePitIdx].slice(0);
			}
			currentPlayerTurn = SIMULATION_CTX.originalPlayerTurn;
			// simulate a bunch of games where the next pit is selected
			if (SIMULATION_CTX.gamesPlayed >= SIMULATION_CTX.gamesToSimulate) {
				SIMULATION_CTX.pitWinProbability[SIMULATION_CTX.ithSelectablePit] = SIMULATION_CTX.gamesWon / SIMULATION_CTX.gamesPlayed;
				console.log("done simulating games, found win % of [" + SIMULATION_CTX.gamesWon + "/" + SIMULATION_CTX.gamesPlayed + " -> " + roundToDecimalPlaces(SIMULATION_CTX.pitWinProbability[SIMULATION_CTX.ithSelectablePit], 3) + "]");
				SIMULATION_CTX.ithSelectablePit += 1;
				if (SIMULATION_CTX.ithSelectablePit < SIMULATION_CTX.selectablePits.length) {
					console.log("simulating games from this point after selecting pit [" + SIMULATION_CTX.selectablePits[SIMULATION_CTX.ithSelectablePit].index + "]...");
				}
				SIMULATION_CTX.gamesPlayed = 0.0;
				SIMULATION_CTX.gamesWon = 0.0;
			}
		// for the initial state, just increment i here
		} else if (SIMULATION_CTX.ithSelectablePit == -1) {
			SIMULATION_CTX.ithSelectablePit += 1;
			if (SIMULATION_CTX.ithSelectablePit < SIMULATION_CTX.selectablePits.length) {
				console.log("simulating games from this point after selecting pit [" + SIMULATION_CTX.selectablePits[SIMULATION_CTX.ithSelectablePit].index + "]...");
			}
		}
		// simulate the game again
		if (SIMULATION_CTX.ithSelectablePit < SIMULATION_CTX.selectablePits.length) {
			//console.log("simulating games from this point after selecting pit [" + SIMULATION_CTX.selectablePits[SIMULATION_CTX.ithSelectablePit].index + "]...");
			frameRate(ANIMATION_FPS);
			runningSimulation = true;
			selectPitForPlay(pits[SIMULATION_CTX.selectablePits[SIMULATION_CTX.ithSelectablePit].index]);
			while (currentState != GAME_OVER) {
				draw();
			}
			// return control to the main thread here, after simulating
			//   this game

		// if we are done simulating games for this pit, reset these things
		//   to trigger the simulations for the next pit, but DO NOT
		//   set SIMULATION_CTX.ithSelectablePit = -1 here, or else we'll
		//   keep looping over the pits forever -- set that after playing
		//   the next move
		} else {
			currentState = WAITING_FOR_PLAYER;
			runningSimulation = false;
		}

	// if not training this AI player (like when simulating games, or playing
	//   an AI against a human), use the board state to select a pit for play
	} else {
		playAITurn();
	}
}

const MOVE_SELECT_EPSILON = 0.001; // one tenth of one percent chance to pick the move (assuming all outputs sum to ~1.0)
function playAITurn() {
	const ai = ML_PLAYER_NN_BY_INDEX[currentPlayerTurn];
	const selectedPitIndexOffset = getPitIndexForNeuralNetworkOutputIndex(0);
	const inputs = getNNInputs();
	// we don't want to get stuck here, so:
	// - replace any output less than some >0 epsilon with epsilon (including any negatives)
	// - replace any output for a pit with 0 seeds with 0
	const outputs = ai.process_input(inputs).map((val,idx) => pits[idx+selectedPitIndexOffset].seeds.length > 0 ? Math.max(MOVE_SELECT_EPSILON, val) : 0.0);
	//if (currentState == ADJUSTING_NEURAL_NETWORK_WEIGHTS) {
	//	console.log("nn outputs are [" + outputs.map((v) => roundToDecimalPlaces(v, 4)) + "]...");
	//}
	// we use each move's probability as the chance to pick that move...
	//   but the probabilities don't necessarily add up to 1.0
	const probSum = outputs.reduce((acc,val) => acc + val);
	const randVal = fasterRandom(0.0, probSum);
	let randReachSum = 0.0;
	let selectedPitIndex = 0;
	for (; selectedPitIndex < outputs.length; selectedPitIndex++) {
		randReachSum += outputs[selectedPitIndex];
		if (randReachSum >= randVal) {
			break;
		}
	}
	//console.log("nn outputs are [" + outputs.map((v,idx) => selectedPitIndex == idx ? "-->" + roundToDecimalPlaces(v, 4) : roundToDecimalPlaces(v, 4)) + "]");
	selectPitForPlay(pits[selectedPitIndex + selectedPitIndexOffset]);
}

/*
function playAITurnSlow() {
	const ai = ML_PLAYER_NN_BY_INDEX[currentPlayerTurn];
	const inputs = getNNInputs();
	const outputs = ai.process_input(inputs);
	//if (currentState == ADJUSTING_NEURAL_NETWORK_WEIGHTS) {
	//	console.log("nn outputs are [" + outputs.map((v) => roundToDecimalPlaces(v, 4)) + "]...");
	//}
	let selectedPitIndex = -1;
	const selectedPitIndexOffset = getPitIndexForNeuralNetworkOutputIndex(0);
	// we use each move's probability as the chance to pick that move...
	//   so if all moves have very very low probability, we could loop
	//   absolutely forever.  in that case, just pick any of them.
	for (let tries = 0; tries < 1000; tries++) {
		for (let i = 0; i < outputs.length; i++) {
			if (pits[i+selectedPitIndexOffset].seeds.length == 0) {
				continue;
			}
			if (fasterRandom(0.0, 1.0) < outputs[i]) {
				selectedPitIndex = i+selectedPitIndexOffset;
				break;
			}
		}
		if (selectedPitIndex > 0) {
			break;
		}
	}
	if (selectedPitIndex == -1) {
		for (let i = 0; i < pitsPerSide; i++) {
			if (pits[i+selectedPitIndexOffset].seeds.length > 0) {
				selectedPitIndex = i+selectedPitIndexOffset;
				//console.log("no pit had high enough probability to be picked, so we just picked the first valid pit: " + selectedPitIndex);
				break;
			}
		}
	}
	selectPitForPlay(pits[selectedPitIndex]);
}
*/

// player 0 -> ith pit + 1
// player 1 -> ith pit + 8
function getPitIndexForNeuralNetworkOutputIndex(outputIndex) {
	return outputIndex + 1 + (currentPlayerTurn * (pitsPerSide + 1));
}

function adjustWeightsInChunks() {
	const ai = ML_PLAYER_NN_BY_INDEX[currentPlayerTurn];
	ai.learn(adjustWeightsChunkIterations, recentInputsToTrainOn, recentOutputsToTrainOn);
	adjustWeightsChunkCounter += 1;
	const postLearnDist = ai.get_current_outputs_dist(recentInputsToTrainOn, recentOutputsToTrainOn);
	const postLearnDistAvg            = roundToDecimalPlaces(postLearnDist/recentInputsToTrainOn.length, 8);
	const postLearnDistAvgRoundedMore = roundToDecimalPlaces(postLearnDist/recentInputsToTrainOn.length, 5);
	learningTotalIterations += adjustWeightsChunkIterations;
	if (adjustWeightsChunkCounter % 100 == 0) {
		console.log("after " + learningTotalIterations + " iterations, average postLearnDist [" + postLearnDistAvg + "]");
	}
	// after running all adjustment chunks, move to the next input/output pair in the training data
	if (adjustWeightsChunkCounter >= adjustWeightsChunks) {
		if (
				randomNudgesForThisTrainingData > 1 ||
				postLearnDistAvg <= (1.1 * stopTrainingDistanceForSingleMove) ||
				postLearnDistAvgRoundedMore > prevAvgDistRounded ||
				(!shouldDoRandomNudging && prevAvgDistRounded == postLearnDistAvgRoundedMore)) {
			// now that we are done adjusting weights, use the adjusted AI to play a move
			playAITurn();
			SIMULATION_CTX.ithSelectablePit = -1;
			return;
		} else {
			// we haven't reached the desired level of accuracy, so keep training,
			//   but nudge all weights+biases if nothing's changed
			if (prevAvgDistRounded == postLearnDistAvgRoundedMore) {
				if (shouldDoRandomNudging) {
					console.log("nothing has changed after this set of training epochs, so giving all weights+biases in the network a nudge");
					doRandomNudge(randomNudgingFactor);
					randomNudgesForThisTrainingData++;
					prevAvgDistRounded = Infinity;
				}
			// this is the common case: do another set of iterations, but save
			//   the average dist/err so we can tell if its still decreasing
			} else {
				prevAvgDistRounded = postLearnDistAvgRoundedMore;
			}
			adjustWeightsChunkCounter = 0;
		}
	}
	statusParagraph.html(
		"aiTrainingGamesToRun=" + aiTrainingGamesToRun + " | " +
		"recentOutputsToTrainOn=" + recentOutputsToTrainOn.length + " | " +
		"learningTotalIterations=" + learningTotalIterations.toLocaleString() + " | " +
		"done learning chunk " + adjustWeightsChunkCounter + " of " + adjustWeightsChunks + " (avg dist: " + postLearnDistAvg + ")");
}

// move all weights and biases up or down by 1+nudgeSize,
//   so 0.1 does a 10% nudge for everything
let doRandomNudge = function(nudgeSize) {
	for (const mlPlayerIndex of TRAIN_ML_PLAYER_INDEXES) {
		ML_PLAYER_NN_BY_INDEX[mlPlayerIndex].randomNudge(nudgeSize);
	}
};

function roundToDecimalPlaces(value, decimals) {
	const tenPow = Math.pow(10.0, decimals);
	return Math.round(value * tenPow) / tenPow;
}

function restartGame() {
	for (const pit of pits) {
		if (pit.isBank) {
			pit.resetWithNewSeeds(0);
		} else {
			pit.resetWithNewSeeds(INITIAL_SEEDS_IN_PIT);
		}
	}

	// randomize player turn
	currentPlayerTurn = round(fasterRandom(0,1));
	currentState = WAITING_FOR_PLAYER;
}

		</script>
	</head>
	<body style="background-color: rgb(120,120,120)">
		<main style="text-align:center; padding: 2.0rem;">
		</main>
	</body>
</html>