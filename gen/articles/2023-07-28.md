
<!-- Copyright 2023 Phil Thompson. All Rights Reserved.  As noted in the License section of this repository's readme.md file, this file and its corresponding public HTML file, and all other articles, article files, and images, are distributed under traditional copyright.  The repository source code and other files are distributed under the MIT license. -->

[//]: # (gen-title: Trying Generative Fill in Photoshop)

[//]: # (gen-title-url: Trying-Generative-Fill-in-Photoshop)

[//]: # (gen-keywords: photoshop, generative fill, AI, artificial intelligence, machine learning, ML, birding, osprey, )

[//]: # (gen-description: Showing results of my test of Photoshop's new generative fill feature.)

[//]: # (gen-meta-end)

<a href="${THIS_ARTICLE}"><img style="float: left" class="width-resp-50-100" src="${SITE_ROOT_REL}/s/img/2023/20230728-osprey-gen-fill-ps-and-ts.jpg"/></a> 

The year is 2023.  Machine learning is all the rage (<a href="${SITE_ROOT_REL}/2023/Programming-in-the-era-of-ChatGPT.html">for good reason, I believe</a>).

Computer-generated graphics is one area where the computing industry is experimenting with ML.  I recently installed the Photoshop beta, which gives access to this tech through <a target="_blank" href="https://helpx.adobe.com/photoshop/using/generative-fill.html">its new "generative fill" feature</a>.  I tested the feature out on some recent photos of mine.

[more](more://)

I'll show my results on a photo I took of an Osprey.  Here's the original frame I captured, with a white border:

<p class="wrap-wider-child"><img class="center-block width-100" src="${SITE_ROOT_REL}/s/img/2023/20230728-osprey-gen-fill-orig.jpg"/></p>

As you can see, I wasn't able to fit the bird's entire wingspan into the shot.  I used generative fill after expanding the image, and picked my favorite from three ML-drawn options:

<p class="wrap-wider-child"><img class="center-block width-100" src="${SITE_ROOT_REL}/s/img/2023/20230728-osprey-gen-fill-ps-initial.jpg"/></p>

The results look great when shrunk down to 15% size here.  The length and positioning of the feathers looks nice, and the added sky background blends in fine.  At 100% scale though, it doesn't look so perfect.  The first problem I noticed was that the drawn-in feather tips appear out-of-focus.  The rest of the wings are fairly sharp so I'm not sure why Photoshop drew them in this way:

<p class="wrap-wider-child"><img class="center-block width-100" src="${SITE_ROOT_REL}/s/img/2023/20230728-osprey-gen-fill-ps-initial-crop.jpg"/></p>

I also noticed that the background didn't blend in as smoothly as I'd hoped.  I could see the faint outline of where the original frame was.  By applying a camera raw filter that increases the "Texture," "Clarity," and "Dehaze," we can see how the generated sky area is subtly different from the existing sky:

<p class="wrap-wider-child"><img class="center-block width-100" src="${SITE_ROOT_REL}/s/img/2023/20230728-osprey-gen-fill-ps-initial-reveal.jpg"/></p>

This means that further edits to the image could potentially reveal this lack of continuity from the original sky pixels to the drawn-in pixels.  This is less of an issue if generative fill is applied as the final step, but I felt like the sky wasn't good enough to be used in the final image.  Instead, I created an entirely new sky gradient using the original sky colors, added some noise, and then pasted the Osprey on top of that:

<p class="wrap-wider-child"><img class="center-block width-100" src="${SITE_ROOT_REL}/s/img/2023/20230728-osprey-gen-fill-ps.jpg"/></p>

To fix the blurred feather tips, I then brought the image into Topaz Sharpen AI.  I was able to use Sharpen AI's masking feature to selectively sharpen the feather tips:

<p class="wrap-wider-child"><img class="center-block width-100" src="${SITE_ROOT_REL}/s/img/2023/20230728-osprey-gen-fill-ps-and-ts-crop.jpg"/></p>

If you know where to look on the feathers you can still see where the original image ends and the ML-drawn pixels begin, but this isn't really a problem when the entire image is viewed as a whole:

<p class="wrap-wider-child"><img class="center-block width-100" src="${SITE_ROOT_REL}/s/img/2023/20230728-osprey-gen-fill-ps-and-ts.jpg"/></p>

Overall I'm happy, but not blown away, with the results generated by this new feature.  I tried it out on <a href="${SITE_ROOT_REL}/gallery/gallery-2023-07-26-112416.html">a few other images in a recent gallery</a>.  (Of the three Osprey shots I tried it on, this one worked the best.)  Generative fill did work very well for replacing some objects (birds) in photos with background content, and you can see those results in that linked gallery.  I think painting over unwanted areas is the best initial use of this feature.

I also think that in a few years generative fill will perform much better.  It will definitely be able to generate perfectly plausible "canvas extends" like I attempted to use here.  I'm not sure what that means for the future of photography, but it'll be fun to see where this goes.
