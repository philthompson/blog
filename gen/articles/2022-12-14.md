
<!-- Copyright 2022 Phil Thompson. All Rights Reserved.  As noted in the License section of this repository's readme.md file, this file and its corresponding public HTML file, and all other articles, article files, and images, are distributed under traditional copyright.  The repository source code and other files are distributed under the MIT license. -->

[//]: # (gen-title: Advent of Code 2022)

[//]: # (gen-title-url: Advent-of-Code-2022)

[//]: # (gen-keywords: advent, code, 2022, programming, puzzle, python, journal)

[//]: # (gen-description: My journal of my experience trying Advent of Code for the first time, in 2022.)

[//]: # (gen-meta-end)

<a href="${THIS_ARTICLE}"><img style="float: left" class="width-resp-50-100" src="${SITE_ROOT_REL}/img/20221214.jpg"/></a> This is my first year trying the <a target="_blank" href="https://adventofcode.com/2022">Advent of Code</a>.  I'll be keeping my journal here.

I'd heard about it on podcasts on the <a target="_blank" href="https://twit.tv">TWiT network</a> for a few years now (specifically, <a target="_blank" href="https://twit.tv/shows/security-now">Security Now</a>), and I'd like to see for myself how hard the puzzles get toward the end.

I am writing my solutions in python 3 &mdash; usually just the minimum effort to get the answer, perhaps with some comments here and there.  I am not looking for hints on reddit or anything, as the Advent of Code site suggests.  As I'm writing this now, I am stuck on Day 11's part 2 challenge, so I'll be staying away from reddit until I figure that out.

I've made my code available <a target="_blank" href="https://github.com/philthompson/advent-of-code/tree/master/2022">on GitHub</a>.  Obviously, *THERE ARE SPOILERS* ahead.  Don't continue reading if you want to solve these puzzles yourself.

[more](more://)

#### <a target="_blank" href="https://adventofcode.com/2022/day/1">Day 1: Calorie Counting</a>

Trivial.

#### <a target="_blank" href="https://adventofcode.com/2022/day/2">Day 2: Rock Paper Scissors</a>

Trivial.

#### <a target="_blank" href="https://adventofcode.com/2022/day/3">Day 3: Rucksack Reorganization</a>

Trivial.

#### <a target="_blank" href="https://adventofcode.com/2022/day/4">Day 4: Camp Cleanup</a>

Trivial

#### <a target="_blank" href="https://adventofcode.com/2022/day/5">Day 5: Supply Stacks</a>

Ohh, a tad harder.

#### <a target="_blank" href="https://adventofcode.com/2022/day/6">Day 6: Tuning Trouble</a>

This was easier than expected.

#### <a target="_blank" href="https://adventofcode.com/2022/day/7">Day 7: No Space Left On Device</a>

This one was a bit more complex.  The trickiest part was finally realizing the puzzle solution was looking for directories of size "at most 100000," not "at least 100000."  So I've learned to read these specifications very closely.

#### <a target="_blank" href="https://adventofcode.com/2022/day/8">Day 8: Treetop Tree House</a>

Straightforward, a bit easier than the previous day.

#### <a target="_blank" href="https://adventofcode.com/2022/day/9">Day 9: Rope Bridge</a>

Seemed to be not any easier or harder than Day 8.  For part 2, I thought we'd progress from one rope segment to two, not to 9!  This was as fun one.

#### <a target="_blank" href="https://adventofcode.com/2022/day/10">Day 10: Cathode-Ray Tube</a>

This was fun to implement.  Part 1 was pretty easy, and it very nicely set things up for part 2.  For part 2, it was a bit odd how the display pixels and cycles were numbered with a 1-based system, while a zero-based system was actually needed to get the proper result.

#### <a target="_blank" href="https://adventofcode.com/2022/day/11">Day 11: Monkey in the Middle</a>

Part 1 was straightforward.  Part 2, on the other hand, seems impossible at the moment.  I must be missing something.  We are squaring some values on each iteration, so the worry reduction step cannot be a subtraction, right?  I wrote some code to brute force a bunch of tests.  I don't like how the “puzzle” is worded.  It's not clear.  I can think of a zillion ways to reduce worry, and I don't like how I am doing "guess and check" to try to duplicate the example results.  The worry reduction part should be more well-defined or bounded in some way.

#### <a target="_blank" href="https://adventofcode.com/2022/day/12">Day 12: Hill Climbing Algorithm</a>

This was fun to solve.  I used a simple recursive function.  The input was large enough to exceed python's recursion depth limit, so I came up with a quick way to save function parameters/state out to a separate list and execute the recursion in smaller chunks.

#### <a target="_blank" href="https://adventofcode.com/2022/day/13">Day 13: Distress Signal</a>

This might have been the most challenging so far, but still not too bad.  I had a little trouble with the "ran out of items to compare" situations but luckily I was able to spot my bug and finish both parts more quickly than expected.

#### <a target="_blank" href="https://adventofcode.com/2022/day/14">Day 14: Regolith Reservoir</a>

This was another fun one.  I like these puzzles that are straightforward and produce some cool-looking output.  Writing this out to the terminal as an animation would be fun.

#### <a target="_blank" href="https://adventofcode.com/2022/day/15">Day 15: Beacon Exclusion Zone</a>

This was fun to work on, and deceptively challenging due to the large search space.  My first naive solution was straightforward to write, and I was able to easily replicate the example results.  That example-solving code was keeping all coordinates in memory, so it wasn't viable for solving the full part 1 puzzle.  But it was pretty easy to use what I'd written to solve part 1 after a little re-arranging.  I thought I might have to expand the x-axis bounds a little beyond the sensors located at the extremes to find all the eliminated coordinates, and indeed that was necessary.<br/><br/>For part 2, I wrapped my part 1 solution in a loop.  I started one instance of my initial, naive python code at `y=0`, going row-by-row up to `y=4_000_000`.  It was taking forever, so I started a second instance of python at `y=4_000_000` going backwards down to `y=0`.  Those were still taking forever.  I made my code a little bit more efficient by storing each sensor's beacon distance at instantiation time instead of calculating it whenever asked for.  Then I started two more instances at the midpoint (`y=2_000_000`) where one progresses up toward `y=3_000_000` and one down toward `y=1_000_000`.  My back of the napkin math showed this would take 115 days to complete, assuming 10 seconds per row, with the search space split among 4 processor cores.  I'd have a 50% chance to have a solution before 58 days have passed.<br/><br/>Obviously, a better algorithm was needed.  Firstly, I could eliminate some sensors from consideration for a line: if they were too far away, they'd never eliminate any x-coordinates on that line.  This change was quick to make.  This change alone allowed my code to run at 2x or 3x the original speed, meaning would take around 10 days to complete if I split the search space up across 8 processor cores.<br/><br/>The final optimization was to find only the edges where each sensor's "diamond of elimination" touches each y-coordinate line.  I could then eliminate all x-coordinates between those edges, without having to compute and check each one.  To accomplish this, I wrote a class that handled integer range subtraction.  All that was needed then was to print out whenever a line ended up without an empty range of candidate x-coordinates &mdash; and only one line did, with only one candidate x-coordinate.  Yay.

#### <a target="_blank" href="https://adventofcode.com/2022/day/16">Day 16: Proboscidea Volcanium</a>

This one took me until the evening of the 19th to finish (for part 1) including in-the-shower epiphanies on two separate days, one of which led me down a wrong path.  There were many false starts, wrong paths and rabbit holes, and re-writes.

I initially had a script that arrived at the correct answer for the example input after just a second of running time.  Building on this idea to try to find a solution for the full input, I spent a lot of time working on heuristics to disqualify bad sequences early on (before lots of time was sunk into them).

The realization that the recursion should fork when the next (flow>0) target valve is selected, not when all possible neighbor valves are visited, finally put me on the right track.

The last stumbling block was my recursive function.  I was trying to output the completed sequence as the function's return value.  This would allow the function to compare its child function call results, and itself only return the best one.  This approach would work fine for a smaller-scale problem, but I quickly ran into recursion depth problems again.  Trying to track the return values when restarting the recursion function was not working.  Eventually I gave up on that idea and used a simpler method of comparing completed sequences against a global "best sequence."  This allows the recursive function to have no return value, so inferior sequences don't need to occupy any memory and can be eliminated as soon as possible.

For part 2, I was able to track the elephant's sequence, location, and target valve separately.  The tricky part was forking the recursive function once for every human+elephant move pair.  Some of the work I'd done following dead-end ideas for part 1 helped here.

I started running my script, which I think tested around 52,000 complete sequences per second.  With a few testing things commented out, and other improvements, I restarted it running at 120,000 complete sequences per second.  This seemed like it would still take a couple weeks of runtime to do an exhaustive search, but to my surprise, after only 9 hours it completed!

#### <a target="_blank" href="https://adventofcode.com/2022/day/17">Day 17: Proboscidea Volcanium</a>

Part 1 was simple, which I did with an object-oriented approach.

For part 2, where a trillion rocks are dropped, I refactored it to eliminate irrelevant rows that are blocked by previously-fallen rocks.  That idea works fine, but the script was of course way too slow to be usable: at 100k rocks per second, it would take 115 days to run.  After lots of incremental improvements, I got the script up to 170k rocks per second, which would take 68 days to run.  I tried refactoring to use bitwise operations, and that turned out slower than the original.  I also tried a refactor to get rid of the object-oriented approach, and again that was slower than my original approach.

I then tried running all these scripts using `pypy` instead of `python` and amazingly my fastest script runs at 1.9 million rocks per second!  While more than 10 times as fast before, it would still take 6 days to drop a trillion rocks.

After a few more iterations, I found that the non-OOP approach was faster when run with `pypy`.  The final script I ran for part 2 drops 3.2 million rocks per second.  It does not instantiate an object for each rock, which provides the biggest speed increase.  It also lowers each rock three steps before checking for previously-dropped rocks.  At 3.2 million rocks per second, the time estimate is 3.6 days to completion.  I think it took closer to 4 full days, since it was occasionally running a bit slow when I checked on it.

I suspect that using bitwise operations is even faster with `pypy`, but rather than work on that I let my solution just run in the background while working on other subsequent puzzles.

#### <a target="_blank" href="https://adventofcode.com/2022/day/18">Day 18: Boiling Boulders</a>

This was was pretty straightforward, and much easier than the previous two days.

For part 1, I used an integer representation of each cube position, which allowed me to populate them in a `set` and easily check all neighboring positions.

Part 2 involved adding a recursive algorithm to find a path to the exterior of the rock.  I added another `set` of discovered positions on the "exterior" of the rock, and another `set` for the cache of visited positions.  The tricky part was realizing I needed to run the algorithm multiple times until the number of discovered "exterior" positions stopped increasing.

#### <a target="_blank" href="https://adventofcode.com/2022/day/19">Day 19: Not Enough Minerals</a>

I was able to complete part 1 with a relatively straightforward "dynamic programming" approach.  As I gather, this is just fancy terminology for my brute force recursive function, which checks for previously-visited states.  This avoids re-computing the same states over and over again.

I was pleasantly surprised to find that python's `namedtuple` could be used as a `dict` key.  I could then use a single `namedtuple` to represent all the state information, and easily check for previously-visited states with the `in` keyword.  This allowed my script to be pretty concise.

For part 2, I ended up changing the main function to run iteratively, not recursively.  The first attempt at a recursive solution, largely the same script from part 1, ran for about 18 hours or so before it was automatically killed (by my MacOS `zsh` shell) while processing the 2nd of 3 blueprints.  I presume it was consuming a ton of memory.

The iterative function saves each reached "state" to the `visited_states` dictionary, and also to a `states_to_try` list, then returns.  The function is then called again after `pop()`ing a saved state from the list.  It runs in a breadth-first fashion, which allows the script to handle all sequences with say 30 minutes remaining, then eliminate all those visited states from the `visited_states` dictionary since no sequence with 30 minutes remaining will be visited again.  Pruning memory like this is not possible with a depth-first recursive approach.

The script calculates a "theoretical maximum" number of geodes each sequence can reach once 7 or fewer minutes remain.  (The maximum is assumed to involve creating geode robots as quickly as possible &mdash; the "7 or fewer" number was a first guess.)  If a sequence can never reach the current "best" sequence's geode quantity, that sequence is terminated early.  When the script ran it terminated a few hundred million sequences early based on this criteria.

In total, when run with `pypy`, the part 2 solution took about 15 hours to run.  It spent most of the time processing 10,000 sequence steps per second or so, and occasionally spiked to a few hundred thousand per second and even well over a million sequence steps per second.  I'm not sure why the running speed was so variable, but it ran fast enough.  If the "theoretical maximum" calculations were started a minute or two earlier, the script would run much faster, I assume.

#### <a target="_blank" href="https://adventofcode.com/2022/day/20">Day 20: Grove Positioning System</a>

This one was relatively straightforward, but I could not figure out why my result for part 1 was not correct.  I implemented a doubly-linked list, and to move each node I proceeded along from node to node the correct number of hops.  I looked at some discussion on reddit, and it dawned on me that what I had failed to realize was that I needed to not count the original node itself (when the number of moves was higher than the total length of the list).  If I had simply first pulled the moving node out of the list, I would not have run into the issue.

Fresh with the "don't count the node itself" requirement in mind, I was able to quickly finish part 2 by moving the huge  required number of moves but modulo `list_length - 1`.

